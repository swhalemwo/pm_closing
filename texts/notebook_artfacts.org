#+PROPERTY: header-args:R :session *R:artfacts*
#+PROPERTY: header-args:R+ :output-dir /home/johannes/Dropbox/phd/papers/closing/notes/artfacts/
#+PROPERTY: header-args:R+ :tangle yes
#+PROPERTY: header-args:R+ :cache yes
#+PROPERTY: header-args:R+ :eval no-export


#+latex_class: notes2

# fucks all the maketitlestuff just to be sure
#+OPTIONS: num:nil
#+OPTIONS: toc:nil
#+OPTIONS: h:5
#+OPTIONS: ^:nil # don't use subscript for underscore
#+options: \n:t # preserver linebreaks

* artfacts notebook

TODO: this stuff is copied from dimred, relies on those objects.. 

#+begin_src R :exports none :results none :cache yes
library(pmdata)
library(jtls)
library(purrr) # looping
library(collapse) # data processing
library(countrycode) # for getting gd_af_size to work
library(wpp2022) # import UN population data for taiwan
data(pop1dt) # actually import Un pop data
library(survival) # survival models
library(Hmisc, include.only = "latexTranslate") # needed for reg table
library(furrr) # parallel processing

c_dirs <- gc_dirs(dir_proj = "/home/johannes/Dropbox/phd/papers/closing/") ## project dirs
PMDATA_LOCS <- gc_pmdata_locs()

dt_pmdb_excl <- gd_pmdb_excl(only_pms = F) %>%
    .[museum_status %in% c("private museum", "closed")] # yeet bad PMs
dt_pmdb <- gd_pmdb(dt_pmdb_excl, verbose = T)


START_YEAR <- 2000
END_YEAR <- 2021

source(paste0(c_dirs$code, "cfg.R"))
source(paste0(c_dirs$code, "vrblcvrg.R"))
source(paste0(c_dirs$code, "regression.R"))
source(paste0(c_dirs$code, "pm_dimred.R")) 

dt_pmx <- gd_pmx(dt_pmdb)

l_pca_dimred_woclosed <- gl_pca_dimred_closed_imputed(dt_pmdb, dt_pmx)
dt_pmtiv <- gd_pmtiv(dt_pmx, l_pca_dimred_woclosed) # time invariant variables

c_lvrs <- list(
  dtti = c("af_size"),
  ## dtti = c(""),
  af_vrbls = c("exhbany", "exhbrollany", "exhbcnt",
               "exhbqntl_cy", "exhbqntl_year","exhbprop_top10_utf",
               "exhbprop_top10_log", "exhbrollsum5", "exhbnNA",
               "exhbrollsum_avg", "exhbqntl_roll"))

                                        # only import selected vrbls to not pollute dt_pmyear


dt_af_size <- gd_af_size(dt_pmx)
dt_pmyear_prep <- gd_pmyear_prep(dt_pmx, dt_pmtiv, c_lvrs) # combine all data sources, as complete as possible
dt_pmyear <- gd_pmyear(dt_pmyear_prep, c_lvrs)

## only get the sim-ple AF measures to get proper comparison
c_lvrs_simaf <- list(
  dtti = c("af_size"),
  ## dtti = c(""),
  af_vrbls = c("exhbany", "exhbrollany"))

dt_pmyear_simaf_prep <- gd_pmyear_prep(dt_pmx, dt_pmtiv, c_lvrs_simaf) 
dt_pmyear_simaf <- gd_pmyear(dt_pmyear_simaf_prep, c_lvrs_simaf)
#+end_src

measures used:
- exhbany: whether a PM has a match in AF (time-invariant; all others are time-varying)
- exhbrollany: whether a PM has had an exhibition in the last 5 years
- exhbcnt: number of exhibition in year
- exhbrollsum5: number of exhibition in last 5 years
- exhbrollsum_avg: exhbrollsum5 divided by number of years is is based on (NAs yeeted)
- exhbnNA: number of (shifted) columns in last 5 years that are NA. this indicates amount of new museums since shifted columns are NA due to trying to lag what doesn't exist.
- exhbqntl_year: empirical quantile (via ecdf) of exhibition count, comparision set is all exhibitions organizations in a year
- exhbqntl_cy: empirical  quantile (via ecdf) of exhibition count, comparision set is all exhibitions organizations in a country-year
- exhbqntl_roll: quantile of exhbrollsum_avg, comparison set is year
- exhbprop_top10_utf: proportion of value of top 10 quantile, untransformed
- exhbprop_top10_log: log(N+1)/quantile(log(N+1)): attempt to scale the exhbprop_top10_utf.. but probably overly complicated



** compare OY coverage by using different filters

#+begin_src R :exports :exports results :results output
c_lvrs_woaf <- list(
  dtti = c(),
  af_vrbls = c())

# compare year coverage between including AF and not including AF
dt_pmyear_waf <- gd_pmyear(dt_pmyear_prep, c_lvrs) # trim down dt to no NAs
dt_pmyear_woaf <- gd_pmyear(dt_pmyear_prep, c_lvrs_woaf)

rbind(dt_pmyear_waf[, .N, year][, src := "waf"], dt_pmyear_woaf[, .N, year][, src := "woaf"]) %>%
    dcast(year ~ src, value.var = "N") %>%
    .[, diff :=  waf - woaf] %>% print(n=30)

#+end_src

#+RESULTS[e80d0963545771f10da9cb389a4d3c8e910259e0]:
#+begin_example
# A data frame: 22 × 4
    year   waf  woaf  diff
   <int> <int> <int> <int>
 1  2000    57    93   -36
 2  2001    76   104   -28
 3  2002    95   120   -25
 4  2003   107   135   -28
 5  2004   114   143   -29
 6  2005   128   157   -29
 7  2006   144   175   -31
 8  2007   189   191    -2
 9  2008   212   212     0
10  2009   234   234     0
11  2010   252   252     0
12  2011   275   276    -1
13  2012   305   308    -3
14  2013   323   323     0
15  2014   334   342    -8
16  2015   352   357    -5
17  2016   368   369    -1
18  2017   336   385   -49
19  2018   359   406   -47
20  2019   412   418    -6
21  2020   429   432    -3
22  2021   417   430   -13
#+end_example


examples for three museums, one without exhibitions (red) and two with quite some (blue, green)

#+name: p_exhb_expl
#+begin_src R :exports results :results output graphics file :file p_exhb_expl.pdf :width 10 :height 5.5
dt_af_size[, .N,  PMDB_ID][N > 20]

dt_af_size[PMDB_ID %in% c(20, 137, 538)] %>%
  melt(id.vars = c("PMDB_ID", "year"), measure.vars = patterns("^exhb"), variable.name = "vrbl") %>%
  ggplot(aes(x=year, y=value, color = factor(PMDB_ID))) +
  geom_line(show.legend = F) +
  facet_wrap(~vrbl, scales = "free") 

#+end_src

#+attr_latex: :width 7in
#+RESULTS[b2dbec5660b437847dc6c8093bfb6f0a50943ff6]: p_exhb_expl
[[file:/home/johannes/Dropbox/phd/papers/closing/notes/artfacts/p_exhb_expl.pdf]]

even tho the red one doesn't have exhibition, its quantile values are not zero.



#+name: p_af_velp
#+begin_src R :exports results :results output graphics file :file p_af_velp.pdf :width 7 :height 5.5
melt(dt_pmyear, id.vars = c("ID", "year"), measure.vars = keep(names(dt_pmyear), ~startsWith(.x, "exhb")),
     variable.name = "vrbl") %>% 
  .[, .(mean_vlu = mean(value)), .(vrbl, year)] %>% 
  ggplot(aes(x=year, y=mean_vlu)) +
  geom_line() + 
  facet_wrap(~vrbl, scales = "free", ncol = 3)
#+end_src

#+attr_latex: :width 7in
#+RESULTS[a2744163230a5ea1bd939c2f2c25fc9ee4df2ce6]: p_af_velp
[[file:/home/johannes/Dropbox/phd/papers/closing/notes/artfacts/p_af_velp.pdf]]

#+begin_src R :exports :exports results :results output
suppressWarnings(melt(dt_pmyear, id.vars = c("ID", "year"), 
                      measure.vars = keep(names(dt_pmyear), ~startsWith(.x, "exhb")),
                      variable.name = "vrbl")) %>%  
  .[, .(mean_vlu = mean(value), sd = sd(value), min = min(value), max= max(value)), vrbl]
#+end_src

#+RESULTS[e92c86d4a9f25288594db9a6756086c53348be25]:
#+begin_example
# A data frame: 11 × 5
   vrbl               mean_vlu    sd    min    max
   <fct>                 <dbl> <dbl>  <dbl>  <dbl>
 1 exhbany               0.660 0.474 0       1    
 2 exhbrollany           0.489 0.500 0       1    
 3 exhbcnt               0.840 1.64  0      14    
 4 exhbqntl_cy           0.447 0.218 0.0833  1    
 5 exhbqntl_year         0.427 0.210 0.244   0.999
 6 exhbprop_top10_utf    0.158 0.310 0       2.8  
 7 exhbprop_top10_log    0.207 0.324 0       1.51 
 8 exhbrollsum5          3.70  6.72  0      65    
 9 exhbnNA               0.621 1.22  0       4    
10 exhbrollsum_avg       0.822 1.43  0      13    
11 exhbqntl_roll         0.271 0.264 0.0579  0.998
#+end_example


#+begin_src R :exports none :results none

l_mdls1 <- list(
  
  ## base model: have to yeet exhbany, which is now default
  r_pop4 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany"), dt_pmyear),
  
  ## with exhbany
  r_afsize1 = coxph(gf_coxph_close(), dt_pmyear),
  r_afsize1_simaf = coxph(gf_coxph_close(), dt_pmyear_simaf),

  r_afsize2 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany", vrbls_to_add = "exhbrollany"), dt_pmyear),
  
  r_afsize3 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany", vrbls_to_add = "exhbqntl_roll"), dt_pmyear),

  r_afsize4 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany", vrbls_to_add = "exhbcnt"), dt_pmyear),

  r_afsize5 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany", vrbls_to_add = "exhbrollsum_avg"), dt_pmyear),

  r_afsize6 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany", vrbls_to_add = "exhbqntl_year"), dt_pmyear)

  ## ## some other models, idk where they're from
  ## r_afsize4 = coxph(Surv(tstart, tstop, closing) ~  exhbany,
  ##                   dt_pmyear),

  ## r_afsize5 = coxph(gf_coxph_close(vrbls_to_yeet = c("founder_dead", "slfidfcn", "an_inclusion")), dt_pmyear),
  
  ## r_afsize6 = coxph(gf_coxph_close(vrbls_to_yeet = c("founder_dead", "slfidfcn", "an_inclusion", "exhbany"),
  ##                                  vrbls_to_add = c("exhbqntl_roll")),
  ##                                  dt_pmyear)
)

## l_mdls2 <- list(
##   ## r_pop4 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##   ##                  slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##   ##                  proxcnt10*popm_circle10 + year, 
##   ##                dt_pmyear),
##   r_pop4 = coxph(gf_coxph_close(vrbls_to_yeet = "exhbany"), dt_pmyear),

##   r2_afsize1 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##                       slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##                       proxcnt10*popm_circle10 + year + exhbany,
##                     dt_pmyear),
##   r2_afsize2 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##                       slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##                       proxcnt10*popm_circle10 + year + exhbrollany,
##                     dt_pmyear),
##   r2_afsize3 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##                       slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##                       proxcnt10*popm_circle10 + year + exhbqntl_roll,
##                      dt_pmyear),
## r2_afsize2k1 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##                     slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##                     proxcnt10*popm_circle10 + year + exhbany,
##                     dt_pmyear[year >= 2000]),
## r2_afsize2k2 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##                     slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##                     proxcnt10*popm_circle10 + year + exhbrollany,
##                   dt_pmyear[year >= 2000]),
## r2_afsize2k3 = coxph(Surv(tstart, tstop, closing) ~ gender + pmdens_cry + I(pmdens_cry^2) + mow +
##                     slfidfcn + founder_dead + muem_fndr_name + an_inclusion +
##                     proxcnt10*popm_circle10 + year + exhbqntl_roll,
##                   dt_pmyear[year >= 2000])
## )

gt_reg_coxph_afsize <- gt_reg_coxph
gt_reg_coxph_afsize2 <- gt_reg_coxph


l_mdlnames_afsize1 <- l_mdlnames_coxph <- c("r_pop4", "r_afsize1", "r_afsize1_simaf", paste0("r_afsize", 2:5))
l_mdlnames_afsize2 <- l_mdlnames_coxph <- c("r_pop4", paste0("r2_afsize", 1:3), paste0("r2_afsize2k", 1:3))

## overwrite the gc_tbls, c_tblargs
gc_tbls <- function() {
  list(
    t_reg_coxph_afsize = list(
      l_mdls = quote(l_mdls1),
      l_mdlnames = quote(l_mdlnames_afsize1),
      caption = "reg results"))
  ## don't need the 2k comparison anymore atm
  ## t_reg_coxph_afsize2 = list(
  ##      l_mdls = quote(l_mdls2),
  ##      l_mdlnames = quote(l_mdlnames_afsize2),
  ##      caption = "reg results comparing full with since 2k"))  
}
c_tblargs <- list()
l_tbls <- list()

## gt_reg_coxph_dimred(l_mdls, l_mdlnames_coxph)
## "t_reg_coxph_afsize2"
map(c("t_reg_coxph_afsize"), ~lapply(c(gtbl, wtbl), \(f) f(.x)))


#+end_src





#+latex: \begin{landscape}


#+INCLUDE: /home/johannes/Dropbox/phd/papers/closing/tables/t_reg_coxph_afsize_wcpF.tex export latex

# #+INCLUDE: /home/johannes/Dropbox/phd/papers/closing/tables/t_reg_coxph_afsize2_wcpF.tex export latex



# exhbqntl_roll is positive and significant, other exhibiiton activity indicators are positive and not significant

# only using years > 2000 (weird values, figure 1) doesn't seem to matter

nothing significant, no substantial change of other coefs


** check correlations of different AF measures

#+name: p_cormat_size
#+begin_src R :exports results :results output graphics file :file p_cormat_size.pdf :width 10 :height 9

library(ggcorrplot) # for correlation matrix
 

dt_pmx <- gd_pmx(dt_pmdb)

cormat_all <- dt_af_size[, .SD, .SDcols = patterns("^exhb")] %>% cor


dt_af_size_mean <- dt_af_size[, lapply(.SD, mean), .SDcols = patterns("quant|exhb|^N"), .(ID = PMDB_ID)] %>%
  .[, c("N") := NULL]

## generate between comparisons
cormat_between <- dt_af_size_mean %>% num_vars %>% .[, ID := NULL] %>% cor(use = "pairwise.complete.obs")
  

## demean
dt_size_within <- fwithin(dt_af_size[, .SD, .SDcols = keep(names(dt_af_size), ~grepl("^exhb", .x))], 
      g = dt_af_size$PMDB_ID) %>% cbind(dt_af_size[, .(PMDB_ID, year)], .)

cormat_within <- cor(dt_size_within[, `:=`(PMDB_ID = NULL, year = NULL)], use = "pairwise.complete.obs")

## combine cormats into one dt
dt_cormat_viz <- imap(list(all = cormat_all, between = cormat_between, within = cormat_within),
                      ~adt(.x, keep.rownames = "vy") %>% melt(id.vars = "vy", variable.name = "vx") %>%
                        .[, src := .y]) %>%
  rbindlist %>%
  .[, `:=`(vx = factor(vx, levels = keep(names(dt_af_size), ~grepl("^exhb", .x))),
           vy = factor(vy, levels = keep(names(dt_af_size), ~grepl("^exhb", .x))))] %>%
  .[!(vx == vy)] %>% 
  na.omit



dt_cormat_viz %>% 
  ggplot(aes(x=vx, y=vy, fill = value)) +
  geom_tile(show.legend = F) +
  geom_text(mapping = aes(label = round(value,2)), size = 2.5) + 
  scale_fill_gradient2(high = "red", low = "blue") +
  facet_wrap(~src, ncol = 2, scales = "free") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

#+end_src

#+attr_latex: :width 9in
#+RESULTS[d840d653ac72289fc4d0f066b8197790435fe8a7]: p_cormat_size
[[file:/home/johannes/Dropbox/phd/papers/closing/notes/artfacts/p_cormat_size.pdf]]

#+latex: \end{landscape}

check whether there is country variation: *what would be the problem exactly?* 

#+name: p_crycheck
#+begin_src R :exports results :results output graphics file :file p_crycheck.pdf :width 4.5 :height 6.5

dt_crycheck <- dt_pmyear[, map(.SD, ~mean(.x)), iso3c, .SDcols = c("exhbany", "exhbrollany", "exhbqntl_roll")]
 
dt_crycheck_order <- copy(dt_crycheck)[, crysum := Reduce(`+`, .SD), .SDcols = patterns("^exhb")] %>%
  .[order(crysum)]
  

dt_crycheck %>%
  melt(id.vars = "iso3c", variable.name = "vrbl") %>%
  .[, iso3c := factor(iso3c, levels = dt_crycheck_order[, iso3c])] %>%
  .[, reg6 := rcd_iso3c_reg6(iso3c)] %>% 
  ggplot(aes(value, y=iso3c, color = vrbl)) +
  geom_point(show.legend = F) +
  facet_grid(reg6~vrbl, scales = "free_y", space = "free_y") +
  theme(axis.text.y = element_text(size = 7))

  
  
#+end_src

#+RESULTS[7b69220ba4c6798fa8081ac024bc9d8d15aab5aa]: p_crycheck
[[file:/home/johannes/Dropbox/phd/papers/closing/notes/artfacts/p_crycheck.pdf]]

hmm interesting that CHE, ITA, FRA are so low within Europe:
maybe composition? many museums included, also already early, so quantiles are high and avg exhbqntl_roll low? 


** compare correlations across different size indicators

hmm the AF variables are pretty much the same, super high correlations among them

but correlation with PCs and other size variables is only around 0.2

tbf that is similar to the correlations between PCs and other original variables, but logged size variables can get to 0.3-0.6, many 0.4, which is kinda more impressive

still, there are three main groups of variables:
- PC based
- AF based
- PMDB numerics

average cross-groups correlations are low, around 0.2;
PMDB numerics and AF have high internal correlations  

possible interpretations:
- at least two groups are based on garbage data
  - PMDB numerics: not longitudinal, could that matter? also SM-heavy, which is subject to trends
    also large gaps, especially in better ones like staff size and collection size -> probably MNAR
  - PCs: based on unstandardized, arbitrary collection
  - AF: yuge longitudinal coverage variation, only 60% of PMs covered
- there isn't a underlying, one-dimensional construct of size 

garbage data: i'm trying to distill measurements out of *garbage data* -> GIGO

lesson: don't work with GARBAGE DATA: even if you get something out in the end (which here I didn't), it will have taken forever
e.g. if I want size, I need actual direct size indicators (floor size, visitors, staff), not a whole bunch of indirect indicators
